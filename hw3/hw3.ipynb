{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f127e1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the data\n",
    "!wget https://people.cs.pitt.edu/~mzhang/cs1699/pacs_dataset.zip\n",
    "!unzip pacs_dataset.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4ba1ae66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys, os, copy, collections\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from skimage import io\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e3e2c58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default configuration\n",
    "task_type = 'training'\n",
    "experiment_name = 'exp'\n",
    "label_type = 'domain'\n",
    "learning_rate = 1e-3\n",
    "weight_decay = 0\n",
    "batch_size = 128\n",
    "epochs = 5\n",
    "LABEL_SIZE = {'domain': 4, 'category': 7}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b86cf0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PACSDataset(Dataset):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        root_dir,\n",
    "        label_type='domain',\n",
    "        is_train=False,\n",
    "        transform=None\n",
    "    ):\n",
    "        self.root_dir = os.path.join(root_dir, 'train' if is_train else 'val')\n",
    "        self.label_type = label_type\n",
    "        self.is_train = is_train\n",
    "        \n",
    "        if transform:\n",
    "            self.transform = transform\n",
    "        else:\n",
    "            self.transform = transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(\n",
    "                    mean=[0.7659, 0.7463, 0.7173],\n",
    "                    std=[0.3089, 0.3181, 0.3470]\n",
    "                ),\n",
    "            ])\n",
    "\n",
    "        self.dataset, self.label_list = self.initialize_dataset()\n",
    "        self.label_to_id = {x: i for i, x in enumerate(self.label_list)}\n",
    "        self.id_to_label = {i: x for i, x in enumerate(self.label_list)}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image, label = self.dataset[idx]\n",
    "        label_id = self.label_to_id[label]\n",
    "        image = self.transform(image)\n",
    "        return image, label_id\n",
    "\n",
    "    def initialize_dataset(self):\n",
    "        \n",
    "        assert os.path.isdir(self.root_dir), \\\n",
    "            f'`root_dir` is not found at {self.root_dir}'\n",
    "\n",
    "        dataset = []\n",
    "        domain_set = set()\n",
    "        category_set = set()\n",
    "        count = 0\n",
    "\n",
    "        for root, dirs, files in os.walk(self.root_dir, topdown=True):\n",
    "            if files:\n",
    "                _, domain, category = root.rsplit('/', maxsplit=2)\n",
    "                domain_set.add(domain)\n",
    "                category_set.add(category)\n",
    "                pbar = tqdm(files)\n",
    "                for name in pbar:\n",
    "                    pbar.set_description(\n",
    "                        f'Processing Folder: domain={domain}, category={category}'\n",
    "                    )\n",
    "                    img_array = io.imread(os.path.join(root, name))\n",
    "                    dataset.append((img_array, domain, category))\n",
    "\n",
    "        images, domains, categories = zip(*dataset)\n",
    "\n",
    "        if self.label_type == 'domain':\n",
    "            labels = sorted(domain_set)\n",
    "            dataset = list(zip(images, domains))\n",
    "        elif self.label_type == 'category':\n",
    "            labels = sorted(category_set)\n",
    "            dataset = list(zip(images, categories))\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                'Unknown `label_type`: Expecting `domain` or `category`.'\n",
    "            )\n",
    "\n",
    "        return dataset, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19238c57",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Folder: domain=sketch, category=giraffe: 100%|██████████| 681/681 [00:16<00:00, 40.28it/s]\n",
      "Processing Folder: domain=sketch, category=person: 100%|██████████| 143/143 [00:02<00:00, 47.71it/s]\n",
      "Processing Folder: domain=sketch, category=house: 100%|██████████| 75/75 [00:01<00:00, 62.37it/s]\n",
      "Processing Folder: domain=sketch, category=guitar: 100%|██████████| 564/564 [00:08<00:00, 69.81it/s] \n",
      "Processing Folder: domain=sketch, category=dog: 100%|██████████| 697/697 [00:15<00:00, 45.42it/s]\n",
      "Processing Folder: domain=sketch, category=horse: 100%|██████████| 736/736 [00:12<00:00, 59.48it/s]\n",
      "Processing Folder: domain=sketch, category=elephant: 100%|██████████| 674/674 [00:13<00:00, 50.86it/s]\n",
      "Processing Folder: domain=art_painting, category=giraffe: 100%|██████████| 254/254 [00:07<00:00, 32.96it/s]\n",
      "Processing Folder: domain=art_painting, category=person: 100%|██████████| 404/404 [00:09<00:00, 41.51it/s]\n",
      "Processing Folder: domain=art_painting, category=house: 100%|██████████| 262/262 [00:05<00:00, 52.20it/s]\n",
      "Processing Folder: domain=art_painting, category=guitar: 100%|██████████| 169/169 [00:05<00:00, 30.38it/s]\n",
      "Processing Folder: domain=art_painting, category=dog: 100%|██████████| 348/348 [00:09<00:00, 35.14it/s]\n",
      "Processing Folder: domain=art_painting, category=horse: 100%|██████████| 179/179 [00:04<00:00, 43.18it/s]\n",
      "Processing Folder: domain=art_painting, category=elephant: 100%|██████████| 227/227 [00:04<00:00, 46.96it/s]\n",
      "Processing Folder: domain=photo, category=giraffe: 100%|██████████| 165/165 [00:03<00:00, 44.60it/s]\n",
      "Processing Folder: domain=photo, category=person: 100%|██████████| 383/383 [00:08<00:00, 44.20it/s]\n",
      "Processing Folder: domain=photo, category=house: 100%|██████████| 243/243 [00:06<00:00, 38.45it/s]\n",
      "Processing Folder: domain=photo, category=guitar: 100%|██████████| 167/167 [00:04<00:00, 36.58it/s]\n",
      "Processing Folder: domain=photo, category=dog: 100%|██████████| 169/169 [00:04<00:00, 41.11it/s]\n",
      "Processing Folder: domain=photo, category=horse: 100%|██████████| 186/186 [00:06<00:00, 29.19it/s]\n",
      "Processing Folder: domain=photo, category=elephant: 100%|██████████| 181/181 [00:03<00:00, 49.39it/s]\n",
      "Processing Folder: domain=cartoon, category=giraffe: 100%|██████████| 314/314 [00:05<00:00, 61.75it/s]\n",
      "Processing Folder: domain=cartoon, category=person: 100%|██████████| 364/364 [00:06<00:00, 56.57it/s]\n",
      "Processing Folder: domain=cartoon, category=house: 100%|██████████| 266/266 [00:05<00:00, 46.82it/s]\n",
      "Processing Folder: domain=cartoon, category=guitar: 100%|██████████| 123/123 [00:02<00:00, 45.09it/s]\n",
      "Processing Folder: domain=cartoon, category=dog: 100%|██████████| 343/343 [00:06<00:00, 53.08it/s]\n",
      "Processing Folder: domain=cartoon, category=horse: 100%|██████████| 299/299 [00:05<00:00, 59.01it/s]\n",
      "Processing Folder: domain=cartoon, category=elephant: 100%|██████████| 411/411 [00:07<00:00, 53.57it/s]\n",
      "/ocean/projects/asc170022p/mtragoza/mambaforge/envs/CS2078/lib/python3.10/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Processing Folder: domain=sketch, category=giraffe: 100%|██████████| 72/72 [00:02<00:00, 34.08it/s]\n",
      "Processing Folder: domain=sketch, category=person: 100%|██████████| 17/17 [00:00<00:00, 26.61it/s]\n",
      "Processing Folder: domain=sketch, category=house: 100%|██████████| 5/5 [00:00<00:00, 43.63it/s]\n",
      "Processing Folder: domain=sketch, category=guitar: 100%|██████████| 44/44 [00:02<00:00, 21.12it/s]\n",
      "Processing Folder: domain=sketch, category=dog: 100%|██████████| 75/75 [00:03<00:00, 22.47it/s]\n",
      "Processing Folder: domain=sketch, category=horse: 100%|██████████| 80/80 [00:01<00:00, 68.11it/s]\n",
      "Processing Folder: domain=sketch, category=elephant: 100%|██████████| 66/66 [00:00<00:00, 68.49it/s]\n",
      "Processing Folder: domain=art_painting, category=giraffe: 100%|██████████| 31/31 [00:01<00:00, 27.80it/s]\n",
      "Processing Folder: domain=art_painting, category=person: 100%|██████████| 45/45 [00:01<00:00, 29.47it/s]\n",
      "Processing Folder: domain=art_painting, category=house: 100%|██████████| 33/33 [00:00<00:00, 49.61it/s]\n",
      "Processing Folder: domain=art_painting, category=guitar: 100%|██████████| 15/15 [00:00<00:00, 46.71it/s]\n",
      "Processing Folder: domain=art_painting, category=dog: 100%|██████████| 31/31 [00:00<00:00, 45.55it/s]\n",
      "Processing Folder: domain=art_painting, category=horse: 100%|██████████| 22/22 [00:00<00:00, 34.76it/s]\n",
      "Processing Folder: domain=art_painting, category=elephant: 100%|██████████| 28/28 [00:00<00:00, 35.57it/s]\n",
      "Processing Folder: domain=photo, category=giraffe: 100%|██████████| 17/17 [00:00<00:00, 34.92it/s]\n",
      "Processing Folder: domain=photo, category=person: 100%|██████████| 49/49 [00:01<00:00, 47.77it/s]\n",
      "Processing Folder: domain=photo, category=house: 100%|██████████| 37/37 [00:00<00:00, 61.46it/s]\n",
      "Processing Folder: domain=photo, category=guitar: 100%|██████████| 19/19 [00:00<00:00, 20.93it/s]\n",
      "Processing Folder: domain=photo, category=dog: 100%|██████████| 20/20 [00:00<00:00, 32.31it/s]\n",
      "Processing Folder: domain=photo, category=horse: 100%|██████████| 13/13 [00:00<00:00, 81.32it/s]\n",
      "Processing Folder: domain=photo, category=elephant: 100%|██████████| 21/21 [00:00<00:00, 31.06it/s]\n",
      "Processing Folder: domain=cartoon, category=giraffe: 100%|██████████| 32/32 [00:00<00:00, 68.73it/s]\n",
      "Processing Folder: domain=cartoon, category=person: 100%|██████████| 41/41 [00:00<00:00, 78.19it/s]\n",
      "Processing Folder: domain=cartoon, category=house: 100%|██████████| 22/22 [00:00<00:00, 63.78it/s]\n",
      "Processing Folder: domain=cartoon, category=guitar: 100%|██████████| 12/12 [00:00<00:00, 89.85it/s]\n",
      "Processing Folder: domain=cartoon, category=dog: 100%|██████████| 46/46 [00:01<00:00, 42.58it/s]\n",
      "Processing Folder: domain=cartoon, category=horse: 100%|██████████| 25/25 [00:00<00:00, 45.59it/s]\n",
      "Processing Folder: domain=cartoon, category=elephant: 100%|██████████| 46/46 [00:01<00:00, 36.92it/s]\n"
     ]
    }
   ],
   "source": [
    "# create datasets and data loaders\n",
    "train_dataset = PACSDataset(\n",
    "    root_dir='pacs_dataset', label_type=label_type, is_train=True\n",
    ")\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, batch_size=batch_size, shuffle=True, num_workers=4\n",
    ")\n",
    "val_dataset = PACSDataset(\n",
    "    root_dir='pacs_dataset', label_type=label_type, is_train=False\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_dataset, batch_size=batch_size, shuffle=False, num_workers=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "19adfff7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AlexNet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 96, kernel_size=(11, 11), stride=(4, 4))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(96, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(256, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.5, inplace=False)\n",
       "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): Linear(in_features=4096, out_features=4, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class AlexNet(nn.Module):\n",
    "    \n",
    "    def __init__(self, config=None):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.features = nn.Sequential(\n",
    "            \n",
    "            nn.Conv2d(3, 96, kernel_size=11, stride=4),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            \n",
    "            nn.Conv2d(96, 256, kernel_size=5, stride=1, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            \n",
    "            nn.Conv2d(256, 384, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(384, 384, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(384, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(9216, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4096, LABEL_SIZE[label_type])\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        z = self.features(x).flatten(1)\n",
    "        return self.classifier(z)\n",
    "\n",
    "AlexNet().forward(torch.zeros(1, 3, 227, 227)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "bab2f722",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Architecture:\n",
      "AlexNet(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 96, kernel_size=(11, 11), stride=(4, 4))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(96, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): Conv2d(256, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): ReLU(inplace=True)\n",
      "    (8): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (9): ReLU(inplace=True)\n",
      "    (10): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Dropout(p=0.5, inplace=False)\n",
      "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Dropout(p=0.5, inplace=False)\n",
      "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): Linear(in_features=4096, out_features=4, bias=True)\n",
      "  )\n",
      ")\n",
      "100%|██████████| 71/71 [00:26<00:00,  2.69it/s]\n",
      "[Epoch 1/5] train accuracy: 0.5693, loss: 1.1854\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.68it/s]\n",
      "[Epoch 1/5] eval accuracy: 0.7427, loss: 0.4846\n",
      "100%|██████████| 71/71 [00:16<00:00,  4.36it/s]\n",
      "[Epoch 2/5] train accuracy: 0.7766, loss: 0.4579\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.70it/s]\n",
      "[Epoch 2/5] eval accuracy: 0.7770, loss: 0.4031\n",
      "100%|██████████| 71/71 [00:16<00:00,  4.26it/s]\n",
      "[Epoch 3/5] train accuracy: 0.8138, loss: 0.4009\n",
      "100%|██████████| 8/8 [00:05<00:00,  1.47it/s]\n",
      "[Epoch 3/5] eval accuracy: 0.8102, loss: 0.4997\n",
      "100%|██████████| 71/71 [00:16<00:00,  4.36it/s]\n",
      "[Epoch 4/5] train accuracy: 0.7716, loss: 0.5637\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.88it/s]\n",
      "[Epoch 4/5] eval accuracy: 0.8195, loss: 0.3860\n",
      "100%|██████████| 71/71 [00:16<00:00,  4.32it/s]\n",
      "[Epoch 5/5] train accuracy: 0.8305, loss: 0.3958\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.73it/s]\n",
      "[Epoch 5/5] eval accuracy: 0.8558, loss: 0.3573\n"
     ]
    }
   ],
   "source": [
    "def model_training(model_class):\n",
    "\n",
    "    best_model = None\n",
    "    best_acc = 0.0\n",
    "\n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    expt_name = 'experiments/{}/{}_lr_{}.wd_{}'.format(experiment_name, label_type, learning_rate, weight_decay)\n",
    "\n",
    "    os.makedirs(expt_name, exist_ok=True)\n",
    "    writer = SummaryWriter(log_dir=expt_name)\n",
    "\n",
    "    configs = {'num_classes': LABEL_SIZE[label_type], 'dropout': 0.5}\n",
    "\n",
    "    model = model_class(configs).to(device)\n",
    "\n",
    "    print('Model Architecture:\\n%s' % model)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss(reduction='mean')\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "    try:\n",
    "        for epoch in range(epochs):\n",
    "            for phase in ('train', 'eval'):\n",
    "                if phase == 'train':\n",
    "                    model.train()\n",
    "                    dataset = train_dataset\n",
    "                    data_loader = train_loader\n",
    "                else:\n",
    "                    model.eval()\n",
    "                    dataset = val_dataset\n",
    "                    data_loader = val_loader\n",
    "\n",
    "                running_loss = 0.0\n",
    "                running_corrects = 0\n",
    "\n",
    "                for step, (images, labels) in enumerate(tqdm(data_loader, file=sys.stdout)):\n",
    "                    images = images.to(device)\n",
    "                    labels = labels.to(device)\n",
    "\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                    with torch.set_grad_enabled(phase == 'train'):\n",
    "                        outputs = model(images)\n",
    "                        _, preds = torch.max(outputs, 1)\n",
    "                        loss = criterion(outputs, labels)\n",
    "\n",
    "                        if phase == 'train':\n",
    "                            loss.backward()\n",
    "                            optimizer.step()\n",
    "\n",
    "                            full_step = epoch * len(dataset) + step\n",
    "                            writer.add_scalar('Loss/{}'.format(phase), loss.item(), full_step)\n",
    "\n",
    "                    running_loss += loss.item() * images.size(0)\n",
    "                    running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "                epoch_loss = running_loss / len(dataset)\n",
    "                epoch_acc = running_corrects.double() / len(dataset)\n",
    "                writer.add_scalar('Epoch_Loss/{}'.format(phase), epoch_loss, epoch)\n",
    "                writer.add_scalar('Epoch_Accuracy/{}'.format(phase), epoch_acc, epoch)\n",
    "                print('[Epoch {}/{}] {} accuracy: {:.4f}, loss: {:.4f}'.format(\n",
    "                    epoch+1, epochs, phase, epoch_acc, epoch_loss\n",
    "                ))\n",
    "\n",
    "                if phase == 'eval':\n",
    "                    if epoch_acc > best_acc:\n",
    "                        best_acc = epoch_acc\n",
    "                        best_model = copy.deepcopy(model.state_dict())\n",
    "                        torch.save(best_model, os.path.join(expt_name, 'best_model.pt'))\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        pass\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "model_training(AlexNet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5f6745",
   "metadata": {},
   "source": [
    "# Part b - Enhanced AlexNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4859fc8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class AlexNetLargerKernel(nn.Module):\n",
    "    \n",
    "    def __init__(self, config=None):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.features = nn.Sequential(\n",
    "            \n",
    "            nn.Conv2d(3, 96, kernel_size=21, stride=8),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.Conv2d(96, 256, kernel_size=7, stride=2, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.Conv2d(256, 384, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(384, 384, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(384, 256, kernel_size=3, stride=2, padding=1),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(9216, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4096, LABEL_SIZE[label_type])\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        z = self.features(x).flatten(1)\n",
    "        return self.classifier(z)\n",
    "\n",
    "AlexNetLargerKernel().forward(torch.zeros(1, 3, 227, 227)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3d82a67e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Architecture:\n",
      "AlexNetLargerKernel(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 96, kernel_size=(21, 21), stride=(8, 8))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(96, 256, kernel_size=(7, 7), stride=(2, 2), padding=(2, 2))\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): Conv2d(256, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): ReLU(inplace=True)\n",
      "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (9): ReLU(inplace=True)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Dropout(p=0.5, inplace=False)\n",
      "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Dropout(p=0.5, inplace=False)\n",
      "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): Linear(in_features=4096, out_features=4, bias=True)\n",
      "  )\n",
      ")\n",
      "100%|██████████| 71/71 [00:18<00:00,  3.81it/s]\n",
      "[Epoch 1/5] train accuracy: 0.6505, loss: 0.8296\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.85it/s]\n",
      "[Epoch 1/5] eval accuracy: 0.7749, loss: 0.5167\n",
      "100%|██████████| 71/71 [00:15<00:00,  4.61it/s]\n",
      "[Epoch 2/5] train accuracy: 0.7832, loss: 0.4833\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.77it/s]\n",
      "[Epoch 2/5] eval accuracy: 0.8164, loss: 0.4563\n",
      "100%|██████████| 71/71 [00:15<00:00,  4.57it/s]\n",
      "[Epoch 3/5] train accuracy: 0.8167, loss: 0.4326\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.72it/s]\n",
      "[Epoch 3/5] eval accuracy: 0.8039, loss: 0.4714\n",
      "100%|██████████| 71/71 [00:22<00:00,  3.23it/s]\n",
      "[Epoch 4/5] train accuracy: 0.7892, loss: 0.5811\n",
      "100%|██████████| 8/8 [00:07<00:00,  1.03it/s]\n",
      "[Epoch 4/5] eval accuracy: 0.8195, loss: 0.4107\n",
      "100%|██████████| 71/71 [00:16<00:00,  4.35it/s]\n",
      "[Epoch 5/5] train accuracy: 0.8191, loss: 0.4453\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.61it/s]\n",
      "[Epoch 5/5] eval accuracy: 0.8008, loss: 0.4299\n"
     ]
    }
   ],
   "source": [
    "model_training(AlexNetLargerKernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c74c594c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class AlexNetAvgPooling(nn.Module):\n",
    "    \n",
    "    def __init__(self, config=None):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.features = nn.Sequential(\n",
    "            \n",
    "            nn.Conv2d(3, 96, kernel_size=11, stride=4),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.AvgPool2d(kernel_size=3, stride=2),\n",
    "            \n",
    "            nn.Conv2d(96, 256, kernel_size=5, stride=1, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.AvgPool2d(kernel_size=3, stride=2),\n",
    "            \n",
    "            nn.Conv2d(256, 384, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(384, 384, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(384, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.AvgPool2d(kernel_size=3, stride=2)\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(9216, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4096, LABEL_SIZE[label_type])\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        z = self.features(x).flatten(1)\n",
    "        return self.classifier(z)\n",
    "\n",
    "AlexNetAvgPooling().forward(torch.zeros(1, 3, 227, 227)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b273e386",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Architecture:\n",
      "AlexNetAvgPooling(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 96, kernel_size=(11, 11), stride=(4, 4))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): AvgPool2d(kernel_size=3, stride=2, padding=0)\n",
      "    (3): Conv2d(96, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): AvgPool2d(kernel_size=3, stride=2, padding=0)\n",
      "    (6): Conv2d(256, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): ReLU(inplace=True)\n",
      "    (8): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (9): ReLU(inplace=True)\n",
      "    (10): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): AvgPool2d(kernel_size=3, stride=2, padding=0)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Dropout(p=0.5, inplace=False)\n",
      "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Dropout(p=0.5, inplace=False)\n",
      "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): Linear(in_features=4096, out_features=4, bias=True)\n",
      "  )\n",
      ")\n",
      "100%|██████████| 71/71 [00:16<00:00,  4.23it/s]\n",
      "[Epoch 1/5] train accuracy: 0.6201, loss: 0.8376\n",
      "100%|██████████| 8/8 [00:06<00:00,  1.21it/s]\n",
      "[Epoch 1/5] eval accuracy: 0.7510, loss: 0.4992\n",
      "100%|██████████| 71/71 [00:16<00:00,  4.36it/s]\n",
      "[Epoch 2/5] train accuracy: 0.8014, loss: 0.4557\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.84it/s]\n",
      "[Epoch 2/5] eval accuracy: 0.7946, loss: 0.5237\n",
      "100%|██████████| 71/71 [00:16<00:00,  4.31it/s]\n",
      "[Epoch 3/5] train accuracy: 0.8230, loss: 0.4402\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.68it/s]\n",
      "[Epoch 3/5] eval accuracy: 0.8133, loss: 0.4092\n",
      "100%|██████████| 71/71 [00:16<00:00,  4.32it/s]\n",
      "[Epoch 4/5] train accuracy: 0.8512, loss: 0.3641\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.79it/s]\n",
      "[Epoch 4/5] eval accuracy: 0.8641, loss: 0.3215\n",
      "100%|██████████| 71/71 [00:27<00:00,  2.60it/s]\n",
      "[Epoch 5/5] train accuracy: 0.8534, loss: 0.3579\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.79it/s]\n",
      "[Epoch 5/5] eval accuracy: 0.8610, loss: 0.3560\n"
     ]
    }
   ],
   "source": [
    "model_training(AlexNetAvgPooling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba0334a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CS2078",
   "language": "python",
   "name": "cs2078"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
